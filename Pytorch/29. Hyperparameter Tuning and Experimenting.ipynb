{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "651d7619-67fe-4611-a06b-015b7b33373e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "torch.set_printoptions(linewidth=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0474f3ef-f6b9-488c-a7b3-6882ed535f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root= './data',\n",
    "    download= True,\n",
    "    train= True,\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c829fc7d-c3c7-4daf-b20f-6b7ae18fe1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b6e9da5-fb4c-46b5-9560-152c874a166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "\n",
    "    def forward(self, t):\n",
    "        t = F.relu(self.conv1(t))\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        t = F.relu(self.conv2(t))\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "\n",
    "        t = t.reshape(-1, 12*4*4)\n",
    "        t = F.relu(self.fc1(t))\n",
    "        t = F.relu(self.fc2(t))\n",
    "        t = self.out(t)\n",
    "        \n",
    "        return t\n",
    "\n",
    "network = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff8f401d-bc12-4616-be98-b9118175fbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Network(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
       "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bc23b27-6e90-44d0-afea-c8dfa652839b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 total_loss 351.918 total_correct 46539\n",
      "epoch 1 total_loss 233.637 total_correct 51354\n",
      "epoch 2 total_loss 213.605 total_correct 52099\n",
      "epoch 3 total_loss 206.150 total_correct 52398\n",
      "epoch 4 total_loss 199.921 total_correct 52623\n",
      "epoch 5 total_loss 196.935 total_correct 52703\n",
      "epoch 6 total_loss 191.175 total_correct 52982\n",
      "epoch 7 total_loss 190.049 total_correct 53056\n",
      "epoch 8 total_loss 188.924 total_correct 53032\n",
      "epoch 9 total_loss 182.076 total_correct 53285\n"
     ]
    }
   ],
   "source": [
    "network = Network()\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100, shuffle=True)\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.01)\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "tb = SummaryWriter(\"runs/FashionMNIST/trained model\")\n",
    "tb.add_image(\"FashionMNIST Images\", grid)\n",
    "tb.add_graph(network, images)\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        images, labels = batch\n",
    "        preds = network(images)\n",
    "        loss = F.cross_entropy(preds, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_correct += get_num_correct(preds, labels)\n",
    "\n",
    "    tb.add_scalar(\"Loss\", total_loss, epoch)\n",
    "    tb.add_scalar(\"Number Correct\", total_correct, epoch)\n",
    "    tb.add_scalar(\"Accuracy\", total_correct/len(train_set), epoch)\n",
    "\n",
    "    tb.add_histogram(\"conv1.bias\", network.conv1.bias, epoch)\n",
    "    tb.add_histogram(\"conv1.weight\", network.conv1.weight, epoch)\n",
    "    tb.add_histogram(\"conv1.weight.grad\", network.conv1.weight.grad, epoch)\n",
    "\n",
    "    print(f\"epoch {epoch} total_loss {total_loss:.3f} total_correct {total_correct}\" )\n",
    "\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0ded884-5e7f-48c8-a979-fc1b22f45a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight \t torch.Size([6, 1, 5, 5])\n",
      "conv1.bias \t torch.Size([6])\n",
      "conv2.weight \t torch.Size([12, 6, 5, 5])\n",
      "conv2.bias \t torch.Size([12])\n",
      "fc1.weight \t torch.Size([120, 192])\n",
      "fc1.bias \t torch.Size([120])\n",
      "fc2.weight \t torch.Size([60, 120])\n",
      "fc2.bias \t torch.Size([60])\n",
      "out.weight \t torch.Size([10, 60])\n",
      "out.bias \t torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, weigth in network.named_parameters():\n",
    "    print(name, \"\\t\", weigth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8242a748-f1e8-46e8-89db-2dd23ba8bccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight.grad \t torch.Size([6, 1, 5, 5])\n",
      "conv1.bias.grad \t torch.Size([6])\n",
      "conv2.weight.grad \t torch.Size([12, 6, 5, 5])\n",
      "conv2.bias.grad \t torch.Size([12])\n",
      "fc1.weight.grad \t torch.Size([120, 192])\n",
      "fc1.bias.grad \t torch.Size([120])\n",
      "fc2.weight.grad \t torch.Size([60, 120])\n",
      "fc2.bias.grad \t torch.Size([60])\n",
      "out.weight.grad \t torch.Size([10, 60])\n",
      "out.bias.grad \t torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, weight in network.named_parameters():\n",
    "    print(f\"{name}.grad\", \"\\t\", weight.grad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6bde82b9-0983-4640-8824-85891eb35063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 total_correct 47494 total_loss 334.805\n",
      "epoch 1 total_correct 51441 total_loss 234.553\n",
      "epoch 2 total_correct 52115 total_loss 214.687\n",
      "epoch 3 total_correct 52540 total_loss 202.426\n",
      "epoch 4 total_correct 52882 total_loss 192.749\n",
      "epoch 5 total_correct 52940 total_loss 192.185\n",
      "epoch 6 total_correct 53008 total_loss 188.406\n",
      "epoch 7 total_correct 53197 total_loss 185.579\n",
      "epoch 8 total_correct 53182 total_loss 183.054\n",
      "epoch 9 total_correct 53337 total_loss 182.899\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "lr = 0.01\n",
    "\n",
    "network = Network()\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
    "optimizer = optim.Adam(network.parameters(), lr=lr)\n",
    "\n",
    "images, lables = next(iter(train_loader))\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "comment = f\"batch_size = {batch_size} lr = {lr}\"\n",
    "tb = SummaryWriter(\"runs/FashionMNIST\", comment=comment)\n",
    "tb.add_image(\"FashionMNIST Images\",grid)\n",
    "tb.add_graph(network, images)\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        images, labels = batch\n",
    "        \n",
    "        preds = network(images)\n",
    "        loss = F.cross_entropy(preds, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * batch_size # if we use different batch\n",
    "        total_correct += get_num_correct(preds, labels)\n",
    "\n",
    "    tb.add_scalar('Loss', total_loss, epoch)\n",
    "    tb.add_scalar(\"Correct\", total_correct, epoch)\n",
    "    tb.add_scalar(\"Accuracy\", total_correct/len(train_set), epoch)\n",
    "\n",
    "    # tb.add_histogram(\"conv1.bias\", network.conv1.bias, epoch)\n",
    "    # tb.add_histogram(\"conv1.weight\", network.conv1.weight, epoch)\n",
    "    # tb.add_histogram(\"conv1.weight.grad\", network.conv1.weight.grad, epoch)\n",
    "\n",
    "    for name, weight in network.named_parameters():\n",
    "        tb.add_histogram(name, weight, epoch)\n",
    "        tb.add_histogram(f\"{name}.grad\", weight.grad, epoch)\n",
    "\n",
    "    print(f\"epoch {epoch} total_correct {total_correct} total_loss {total_loss:.3f}\")\n",
    "\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdabad57-5df8-411c-a06a-3257280a512f",
   "metadata": {},
   "source": [
    "## Looping using different parameters values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "903bdd39-47d3-4154-b1f9-a864160909ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters list\n",
    "batch_size_list = [100, 1000, 10000]\n",
    "lr_list = [0.01, 0.001, 0.0001]\n",
    "\n",
    "# nasted iteration\n",
    "for batch_size in batch_size_list:\n",
    "    for lr in lr_list:\n",
    "        network = Network()\n",
    "        train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
    "        optimizer = optim.Adam(network.parameters(), lr=lr)\n",
    "        for epoch in range(1):\n",
    "            for batch in train_loader:\n",
    "                break\n",
    "                # images, labels = next(iter(train_loader))\n",
    "                \"\"\"\n",
    "                next codes\n",
    "                \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1977663-45fb-4f3a-ab32-915da89997f0",
   "metadata": {},
   "source": [
    "### Better option for doing the same this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4270ee0d-c3e8-43ad-8519-4e99264fe804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.01, 0.001], [100, 1000, 10000], [True, False]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import product\n",
    "parameters = dict(\n",
    "    lr = [0.01,0.001],\n",
    "    batch_size = [100,1000,10000],\n",
    "    shuffle = [True, False]\n",
    ")\n",
    "param_values = [v for v in parameters.values()]\n",
    "param_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31610b99-aef2-4824-a0e5-54d0b97fd0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 100 True\n",
      "0.01 100 False\n",
      "0.01 1000 True\n",
      "0.01 1000 False\n",
      "0.01 10000 True\n",
      "0.01 10000 False\n",
      "0.001 100 True\n",
      "0.001 100 False\n",
      "0.001 1000 True\n",
      "0.001 1000 False\n",
      "0.001 10000 True\n",
      "0.001 10000 False\n"
     ]
    }
   ],
   "source": [
    "for lr, batch_size, shuffle in product(*param_values): # *arg will accept a turple insted of a single value\n",
    "    print(lr, batch_size, shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "472f6c1c-c8e5-42c0-9bba-d84c5003387d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 100 True\n",
      "epoch 0 total_correct 46629 total_loss 35281.992\n",
      "epoch 1 total_correct 51106 total_loss 23920.710\n",
      "epoch 2 total_correct 51802 total_loss 22130.772\n",
      "epoch 3 total_correct 52184 total_loss 21252.583\n",
      "epoch 4 total_correct 52372 total_loss 20496.213\n",
      "epoch 5 total_correct 52599 total_loss 20108.388\n",
      "epoch 6 total_correct 52644 total_loss 19893.620\n",
      "epoch 7 total_correct 52730 total_loss 19610.529\n",
      "epoch 8 total_correct 52884 total_loss 19135.154\n",
      "epoch 9 total_correct 52907 total_loss 19092.968\n",
      "0.01 100 False\n",
      "epoch 0 total_correct 52932 total_loss 19290.478\n",
      "epoch 1 total_correct 53110 total_loss 18676.609\n",
      "epoch 2 total_correct 53001 total_loss 19182.474\n",
      "epoch 3 total_correct 53324 total_loss 18116.596\n",
      "epoch 4 total_correct 53336 total_loss 18178.562\n",
      "epoch 5 total_correct 53252 total_loss 18549.639\n",
      "epoch 6 total_correct 53374 total_loss 17878.157\n",
      "epoch 7 total_correct 53456 total_loss 17947.817\n",
      "epoch 8 total_correct 53397 total_loss 18068.058\n",
      "epoch 9 total_correct 53486 total_loss 17571.421\n",
      "0.01 1000 True\n",
      "epoch 0 total_correct 54236 total_loss 15403.001\n",
      "epoch 1 total_correct 54596 total_loss 14018.317\n",
      "epoch 2 total_correct 54818 total_loss 13503.007\n",
      "epoch 3 total_correct 54898 total_loss 13267.235\n",
      "epoch 4 total_correct 54926 total_loss 13244.293\n",
      "epoch 5 total_correct 55072 total_loss 12823.642\n",
      "epoch 6 total_correct 55149 total_loss 12568.694\n",
      "epoch 7 total_correct 55159 total_loss 12592.461\n",
      "epoch 8 total_correct 55271 total_loss 12180.585\n",
      "epoch 9 total_correct 55299 total_loss 12030.872\n",
      "0.01 1000 False\n",
      "epoch 0 total_correct 55181 total_loss 12543.763\n",
      "epoch 1 total_correct 55348 total_loss 11988.101\n",
      "epoch 2 total_correct 55457 total_loss 11913.818\n",
      "epoch 3 total_correct 55423 total_loss 11786.899\n",
      "epoch 4 total_correct 55347 total_loss 11929.471\n",
      "epoch 5 total_correct 55373 total_loss 11931.192\n",
      "epoch 6 total_correct 55363 total_loss 11792.883\n",
      "epoch 7 total_correct 55194 total_loss 12393.763\n",
      "epoch 8 total_correct 55443 total_loss 11821.654\n",
      "epoch 9 total_correct 55636 total_loss 11280.123\n",
      "0.01 10000 True\n",
      "epoch 0 total_correct 54904 total_loss 13202.427\n",
      "epoch 1 total_correct 55522 total_loss 11418.082\n",
      "epoch 2 total_correct 55793 total_loss 10684.284\n",
      "epoch 3 total_correct 55993 total_loss 10241.640\n",
      "epoch 4 total_correct 56111 total_loss 9825.144\n",
      "epoch 5 total_correct 56236 total_loss 9640.112\n",
      "epoch 6 total_correct 56293 total_loss 9450.992\n",
      "epoch 7 total_correct 56354 total_loss 9342.162\n",
      "epoch 8 total_correct 56412 total_loss 9214.958\n",
      "epoch 9 total_correct 56417 total_loss 9161.496\n",
      "0.01 10000 False\n",
      "epoch 0 total_correct 55746 total_loss 11060.191\n",
      "epoch 1 total_correct 55967 total_loss 10194.101\n",
      "epoch 2 total_correct 56192 total_loss 9640.867\n",
      "epoch 3 total_correct 56325 total_loss 9446.440\n",
      "epoch 4 total_correct 56439 total_loss 9105.823\n",
      "epoch 5 total_correct 56487 total_loss 8989.530\n",
      "epoch 6 total_correct 56604 total_loss 8835.099\n",
      "epoch 7 total_correct 56638 total_loss 8707.501\n",
      "epoch 8 total_correct 56706 total_loss 8599.360\n",
      "epoch 9 total_correct 56709 total_loss 8515.147\n",
      "0.001 100 True\n",
      "epoch 0 total_correct 56500 total_loss 9056.714\n",
      "epoch 1 total_correct 56557 total_loss 8938.127\n",
      "epoch 2 total_correct 56556 total_loss 8873.504\n",
      "epoch 3 total_correct 56503 total_loss 8935.624\n",
      "epoch 4 total_correct 56578 total_loss 8791.070\n",
      "epoch 5 total_correct 56585 total_loss 8738.395\n",
      "epoch 6 total_correct 56669 total_loss 8709.105\n",
      "epoch 7 total_correct 56662 total_loss 8624.257\n",
      "epoch 8 total_correct 56688 total_loss 8567.805\n",
      "epoch 9 total_correct 56625 total_loss 8655.224\n",
      "0.001 100 False\n",
      "epoch 0 total_correct 56681 total_loss 8560.841\n",
      "epoch 1 total_correct 56735 total_loss 8401.481\n",
      "epoch 2 total_correct 56805 total_loss 8346.329\n",
      "epoch 3 total_correct 56780 total_loss 8315.402\n",
      "epoch 4 total_correct 56753 total_loss 8435.432\n",
      "epoch 5 total_correct 56820 total_loss 8303.650\n",
      "epoch 6 total_correct 56894 total_loss 8102.241\n",
      "epoch 7 total_correct 56901 total_loss 8101.004\n",
      "epoch 8 total_correct 56879 total_loss 8073.310\n",
      "epoch 9 total_correct 56901 total_loss 8020.273\n",
      "0.001 1000 True\n",
      "epoch 0 total_correct 57010 total_loss 7797.721\n",
      "epoch 1 total_correct 57090 total_loss 7631.948\n",
      "epoch 2 total_correct 57124 total_loss 7528.291\n",
      "epoch 3 total_correct 57169 total_loss 7456.929\n",
      "epoch 4 total_correct 57175 total_loss 7444.163\n",
      "epoch 5 total_correct 57181 total_loss 7395.796\n",
      "epoch 6 total_correct 57215 total_loss 7367.808\n",
      "epoch 7 total_correct 57207 total_loss 7375.561\n",
      "epoch 8 total_correct 57260 total_loss 7323.827\n",
      "epoch 9 total_correct 57235 total_loss 7299.208\n",
      "0.001 1000 False\n",
      "epoch 0 total_correct 57199 total_loss 7352.732\n",
      "epoch 1 total_correct 57232 total_loss 7331.539\n",
      "epoch 2 total_correct 57237 total_loss 7309.122\n",
      "epoch 3 total_correct 57264 total_loss 7235.613\n",
      "epoch 4 total_correct 57292 total_loss 7197.600\n",
      "epoch 5 total_correct 57295 total_loss 7173.523\n",
      "epoch 6 total_correct 57298 total_loss 7154.389\n",
      "epoch 7 total_correct 57320 total_loss 7138.012\n",
      "epoch 8 total_correct 57303 total_loss 7131.366\n",
      "epoch 9 total_correct 57310 total_loss 7112.811\n",
      "0.001 10000 True\n",
      "epoch 0 total_correct 57340 total_loss 7060.556\n",
      "epoch 1 total_correct 57382 total_loss 6970.387\n",
      "epoch 2 total_correct 57406 total_loss 6925.483\n",
      "epoch 3 total_correct 57407 total_loss 6898.506\n",
      "epoch 4 total_correct 57418 total_loss 6879.278\n",
      "epoch 5 total_correct 57419 total_loss 6858.756\n",
      "epoch 6 total_correct 57424 total_loss 6841.377\n",
      "epoch 7 total_correct 57433 total_loss 6830.389\n",
      "epoch 8 total_correct 57435 total_loss 6819.288\n",
      "epoch 9 total_correct 57454 total_loss 6807.974\n",
      "0.001 10000 False\n",
      "epoch 0 total_correct 57382 total_loss 6945.101\n",
      "epoch 1 total_correct 57414 total_loss 6896.636\n",
      "epoch 2 total_correct 57432 total_loss 6822.806\n",
      "epoch 3 total_correct 57431 total_loss 6809.316\n",
      "epoch 4 total_correct 57456 total_loss 6778.385\n",
      "epoch 5 total_correct 57466 total_loss 6774.913\n",
      "epoch 6 total_correct 57457 total_loss 6754.996\n",
      "epoch 7 total_correct 57461 total_loss 6749.954\n",
      "epoch 8 total_correct 57463 total_loss 6738.371\n",
      "epoch 9 total_correct 57477 total_loss 6726.863\n"
     ]
    }
   ],
   "source": [
    "network = Network()\n",
    "\n",
    "for lr, batch_size, shuffle in product(*param_values):\n",
    "    print(lr, batch_size, shuffle)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=shuffle)\n",
    "    optimizer = optim.Adam(network.parameters(), lr=lr)\n",
    "\n",
    "    images, lables = next(iter(train_loader))\n",
    "    grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "    comment = f\"batch_size={batch_size} lr={lr} shaffle={shuffle}\"\n",
    "    \n",
    "    tb = SummaryWriter(comment=comment)\n",
    "    tb.add_image(\"FashionMNIST Images\",grid)\n",
    "    tb.add_graph(network, images)\n",
    "\n",
    "    for epoch in range(10):\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            images, labels = batch\n",
    "        \n",
    "            preds = network(images)\n",
    "            loss = F.cross_entropy(preds, labels)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * batch_size # if we use different batch\n",
    "            total_correct += get_num_correct(preds, labels)\n",
    "\n",
    "        tb.add_scalar('Loss', total_loss, epoch)\n",
    "        tb.add_scalar(\"Correct\", total_correct, epoch)\n",
    "        tb.add_scalar(\"Accuracy\", total_correct/len(train_set), epoch)\n",
    "\n",
    "        # tb.add_histogram(\"conv1.bias\", network.conv1.bias, epoch)\n",
    "        # tb.add_histogram(\"conv1.weight\", network.conv1.weight, epoch)\n",
    "        # tb.add_histogram(\"conv1.weight.grad\", network.conv1.weight.grad, epoch)\n",
    "\n",
    "        for name, weight in network.named_parameters():\n",
    "            tb.add_histogram(name, weight, epoch)\n",
    "            tb.add_histogram(f\"{name}.grad\", weight.grad, epoch)\n",
    "\n",
    "        print(f\"epoch {epoch} total_correct {total_correct} total_loss {total_loss:.3f}\")\n",
    "\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65769b9c-02d3-418c-8f1f-4c165e1f82b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
